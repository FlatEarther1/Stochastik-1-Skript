	% ===============================================
% Sogenannte Praeambel: Seiteneinstellungen etc.
% ===============================================

\documentclass[german,10pt,oneside, fleqn, a4paper]{article}

%%% Eingebundene Pakete: werden hier nicht alle gebraucht, schaden aber auch nicht.
\usepackage{hyperref}
\usepackage{graphicx}
\graphicspath{{Praktikumsbericht-Images/}}
\usepackage[german]{babel}
\usepackage{amsmath,amsthm,amssymb,amsfonts,amscd,amsbsy,amsxtra}
\usepackage{epsfig,color}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{fancyheadings}
\usepackage{psfrag}
\usepackage{extarrows}
\usepackage{amsmath}
\usepackage{float}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage[T1]{fontenc} 
\usepackage{ucs}
\usepackage[utf8]{inputenc}
\usepackage[font=scriptsize]{caption}
\usepackage{mathtools}


%%% Neudefinition von Kommandos, um sich Tipp-Arbeit zu ersparen 	 
\newcommand {\Q}	{\mathbb{Q}}
\newcommand {\R}	{\mathbb{R}}
\newcommand {\N}	{\mathbb{N}}
\newcommand{\Ra}	{\Rightarrow}
\newcommand{\La}	{\Leftarrow}
\newcommand{\LRa}{\Leftrightarrow}

%%% Veraenderung des Seitenlayouts
%\setlength{\oddsidemargin}{-1cm}
%\setlength{\evensidemargin}{0cm}
%\setlength{\textwidth}{18cm}
%\setlength{\textheight}{26cm}
%\setlength{\parindent}{0pt}
%\setlength{\topmargin}{-2cm}
%\pagestyle{empty}

\sloppy



%MACROS!!!
\newcommand{\verteq}{\rotatebox{90}{$\,=$}}
\newcommand{\equalto}[2]{\underset{\scriptstyle\overset{\mkern4mu\verteq}{#2}}{#1}}
\newcommand{\lsup}[1][n]{\limsup\limits_{#1\rightarrow\infty}}
\newcommand{\linf}[1][n]{\liminf\limits_{#1\rightarrow\infty}}
\newcommand{\sm}[2][\infty]{\sum\limits_{#2}^{#1}}
\newcommand{\brc}[1]{\left(#1\right)}
\newcommand{\brac}[1]{\lbrace #1\rbrace}
\newcommand{\CUP}[2][\infty]{\bigcup\limits_{#2}^{#1}}
\newcommand{\CAP}[2][\infty]{\bigcap\limits_{#2}^{#1}}
\newcommand{\folge}[3][\N]{\left(#2_#3\right)_{#3\in #1}}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
%\newcommand{\myeq}[2][=]{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\small\sffamily #2}}}{#1}}}
\newcommand{\myeq}[2][=]{\stackrel{\mathclap{\normalfont\tiny\mbox{#2}}}{#1}}
\newcommand{\QED}{\begin{flushright}$\qed$\end{flushright}}
\newcommand{\mat}[1]{\begin{pmatrix}#1\end{pmatrix}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\lp}[1]{\mc{L}^{#1}}
\newcommand{\beweis}{\textbf{Beweis}\\}
\newcommand{\toinf}{\rightarrow\infty}
\newcommand{\fn}{\ \forall n\in\N}
\newcommand{\1}[1]{1_{#1}}
\newcommand{\xn}{\norm{X_n-X}}
% ==============================================
% Start des eigentlichen Dokumentes
% ==============================================
\begin{document}



    
\vspace{0.5cm}
\begin{center}
{\bf \Large Stochastik } \\[2ex]
\end{center} 
\tableofcontents
\pagebreak




\marginpar{1. Vorlesung 16.04.2018}
\part{Grundlagen der Maßtheorethischen Wahrscheinlichkeitstheorie}



\section{0-1 Gesetze}
Gegeben sei ein Wahrscheinlichkeitsraum ($\Omega,\theta,P)$.\\

\subsection{Definition (liminf,limsup)}
Sei $(A_n)_{n\in\N}$ eine Folge in $\theta$. Dann definiert man 
\begin{list}{}{}
\item \(\limsup\limits_{n\rightarrow \infty}A_n=\bigcap\limits_{n=1}^\infty\bigcup\limits_{m=n}^\infty A_m=\lbrace w\in \Omega:w \in A_n\ \infty\text{ -oft}\rbrace\) \\ 
\glqq Unendlich viele der Ereignisse $A_n$ treten ein \grqq.
\item \(\liminf\limits_{n\rightarrow\infty}A_n=\bigcup\limits_{n=1}^\infty\bigcap\limits_{m=n}^\infty A_m=\lbrace w\in \Omega:w \in A_n\text{für schließlich alle n}\rbrace\) \\
\glqq Bis auf endlich viele treten alle der Ereignisse $A_n$ ein \grqq.
\end{list}

\subsection{Bemerkung}
$\liminf\limits_{n\rightarrow\infty}A_n\subseteq \limsup\limits_{n\rightarrow\infty}A_n$

\subsection{Lemma (Borel-Cantelli)}
Sei $(A_n)_{n\in\N}$ eine Folge in $\theta$. 
\begin{list}{}{}
\item $\sum\limits_{n=1}^\infty P(A_n) < \infty\Rightarrow P(\limsup\limits_{n\rightarrow\infty}A_n)=0$
\item Ist $(A_n)_{n\in\N}$ zusätzlich Unabhängig, so gilt $\sum\limits_{n=1}^\infty P(A_n) = +\infty\Leftrightarrow P(\limsup\limits_{n\rightarrow\infty}A_n)=1$
\end{list}

\textbf{Beweis}\\
Es gilt: $P \left(\bigcup\limits_{i=1}^\infty A_i\right) \leq \sum\limits_{i=1}^\infty P(A_i)$\begin{enumerate}[label=(\alph*)]
\item $\forall \varepsilon>0\ \exists N\in\N$ mit\\
$P\left(\limsup\limits_{n\rightarrow\infty}A_n\right)\leq P\left(\bigcup\limits_{m=N}^\infty A_m \right) \leq \sum\limits_{m=N}^\infty P(A_m) \leq \varepsilon$
\item \glqq $\Rightarrow$\grqq:\\
Es gilt $\forall\alpha>0:\ 1-\alpha\leq e^{-\alpha}$ und\\
 $\left(\limsup\limits_{n\rightarrow\infty}A_n\right)^c=\liminf\limits_{n\rightarrow\infty}A_n^c=\bigcup\limits_{n=1}^\infty\bigcap\limits_{m=n}^\infty A_m^c$\\
$P\left(\bigcap\limits_{m=n}^\infty A_m^c\right)=\prod\limits_{m=n}^\infty\left(1-P(A_m)\right)$ wegen Unabhängigkeit und Monotonie. Somit folgt\\
$P((\limsup\limits_{n\rightarrow\infty}A_n)^c)
\leq\sum\limits_{n=1}^\infty P\left(\bigcap\limits_{m=n}^\infty A_m^c\right)
=\sum\limits_{n=1}^\infty\prod\limits_{m=n}^\infty (1-P(A_m))
\leq\sum\limits_{n=1}^m\prod\limits_{m=n}^\infty e^{-P(A_m)}
=\sum\limits_{n=1}^\infty \underbrace{e^{-\overbrace{\sum\limits_{m=n}^\infty P(A_m)}^{\infty}}}_{0}=0$\\\\
\glqq $\Leftarrow$\grqq:$\sum\limits_{n=1}^\infty P(A_n)<\infty$ wäre ein Widerspruch zu a)  \QED
\end{enumerate}

$\limsup , \liminf$ sind Beispiele \textit{Terminaler Ereignise}.





\marginpar{2. Vorlesung 17.04.2018}

\subsection{Definition (Terminale Ereignisse)}
Seien $(\theta_n)_{n\in\N}\subset F$ $\sigma$-Algebren und $T_n=\sigma\left(\bigcup\limits_{m=n}^\infty\theta_m\right)$. \\
Dann heißt $T_\infty:=\bigcap\limits_{n=1}^\infty\theta_n$\\ terminale $\sigma$-Algebra $(\sigma$-Algebra der Terminalen Ereignisse$)$. \\
Terminale Ereignisse hängen nicht von den ersten Endlich vielen $\theta_n$ ab.

\subsection{Beispiel}
Sei $(A_n)_{n\in\N}\in F$. Setze $F_n=\lbrace p,\Omega,A_n,A_n^c\rbrace.$\\
Dann gilt \[\bigcup\limits_{m=n+i}^\infty A_m\in T_n$ $\forall n\in\N, i\in\N_0\].
Somit \[\bigcap\limits_{n=1}^\infty\bigcup\limits_{m=n}^\infty A_m \in T_n \forall n \in \N \Rightarrow\limsup\limits_{n\rightarrow\infty}A_n\in T_\infty\].\\
Da $T_\infty$ $\sigma$-Algebra, gilt auch\\
\[\liminf\limits_{n\rightarrow\infty}A_n=\left(\limsup\limits_{n\rightarrow\infty}A_n^c\right)^c\in T_\infty\]

\subsection{Definition (Unabhängige Mengensysteme)}
Sei $\left(\Omega,\theta,P\right)$ ein Wahrscheinlichkeitsraum und $I\neq\emptyset$ eine Indexmenge. Eine Familie von Mengensystemen $\left(\varphi_n\right)_{n\in\N}$ mit $\varphi_i \subseteq\theta$  heißt unabhängig, falls $\forall y\subseteq I, \vert y \vert < \infty, y\neq\emptyset$ gilt \\
\[P\left(\bigcap\limits_{j\in J}A_j\right)=\prod\limits_{j\in J}P\left(A_j\right)$ $\forall A_j \in\varphi_j\]\\
 \textbf{Beachte}: Sei $\left( x_i \right)_{i\in I}$ eine Familie von Zufallsvariablen mit $x_i:\left(\Omega,
\theta,P\right)\mapsto\left(\Omega_i,\theta_i \right)$, dann sind diese Unabhängig genau dann, wenn die Familie von $\sigma$-Algebren $\left(x_i^{-1}\left(\theta_i\right)\right)_{i\in I}$ unabhängig ist.

\subsection{Satz (0-1 Gesetze von Kolmogorov)}
Sei $\left(\theta_n\right)_{n\in\N}$ eine Folge unabhängiger $\sigma$-Algebren, $\theta_n\subseteq\theta$. Dann gilt\\
\[P\left(A\right)\in \lbrace 0,1\rbrace\ \forall A \in T_\infty\] \\

\textbf{Beweis:}\\
Für $A\in T_\infty$ setze $\mc{D}=\lbrace P\in\sigma\left(\bigcup\limits_{n=1}^\infty F_n\right):\text{ P ist unabhängig von }A\rbrace$. Es genügt zu zeigen: $T_\infty\subseteq \mc{D}$. Dann ist $A$ unabhängig von $A$, und somit $P(A)=P(A\cap A)=P(A)^2$ und somit $P(A)\in\lbrace 0,1 \rbrace$.\\
Es gilt: $T_{n+1}$ und $G_n:=\sigma(\bigcup\limits_{i=1}^n\theta_i)$ sind unabhängig.\\
Da $A\in T_{n+1}$ folgt $G_n\subseteq \mc{D}\ \forall n\in\N\Rightarrow G_0:=\bigcup\limits_{n=1}^\infty G_n\subseteq \mc{D}$. Wegen $G_n\subseteq G_{n+1}$ ist $G_0$ $\cap$-stabil. Mit dem Eindeutigkeitssatz für Maße sind folglich\\
    $\vartheta:\sigma(G_0)\rightarrow\R^+,\ \ G\mapsto P(G\cap A)$\\
    $\mu:\sigma(G_0)\rightarrow\R^+,\ \ G\mapsto P(G)P(A)$ identische Maße.
$\Rightarrow\sigma(G_0)\subseteq \mc{D}$.
Offensichtlich gilt $T_n\subseteq\sigma(G_0)\ \forall n\in\N$\\
$\Rightarrow T_\infty\subseteq\sigma(G_0)\subseteq \mc{D}$.\QED	

\subsection{Korollar}
Sei $\left(A_n\right)_{n\in\N}$ eine Folge unabhängiger Ereignisse. Dann gilt
\[P\left(\limsup\limits_{n\rightarrow\infty}A_n\right)\in\lbrace 0,1\rbrace\]

\subsection{Korollar}
Sei $X:\left(\Omega,\theta\right)\rightarrow\left(\bar\R,B\left(\bar\R\right)\right)$ eine $T_\infty$-Messbare Zufallsvariable. Dann gibt es eine Konstante $c\in\R$ mit $P\left(X=c\right)=1$.\\\\
\textbf{Beweis}\\
$A_q:=\lbrace X\leq q\rbrace\in T_\infty\ \forall q\in \Q\Rightarrow P(A_q)\in\lbrace 0,1\rbrace$ und $P(A-q)$ monoton wachsend in $q$. Setze $c:=\inf\lbrace q\in\Q:P(A_q)=1\rbrace$. Dann folgt \\
$P(X<c)=P(\bigcup\limits_{\substack{q<c\\q\in\Q}}A_q)=0$\\
$P(X>c)=P(\bigcup\limits_{\substack{q>c\\q\in\Q}}A_q)=0$\\$\Rightarrow P(X=c)=1$\QED

\subsection{Beispiel}
Sei $\left(X_n\right)_{n\in\N}$ eine Folge reeller Zufallsvariablen und $\alpha \searrow_{n\rightarrow\infty}0$. Dann gilt:
\[ P\left(\underbrace{\lbrace\omega:\lim\limits_{N\rightarrow\infty} \alpha_N\sum\limits_{i=1}^NX_i\left(\omega\right)=0\rbrace}_{=:A}\right)\in\lbrace 0,1 \rbrace\]

\textbf{Beweis}\\
Sei $\theta_n=X_n^{-1}(B(\R))$. Dann ist $(\theta_n)_{n\in\N}$ eine unabhängige Folge von $\sigma$-Algebren.\\
$\alpha_N\sum\limits_{i=1}^\infty X_i=\underbrace{{\alpha_N}\sum\limits_{i=1}^n X_i}_{\xrightarrow[N\rightarrow\infty]{}0}+\underbrace{{\alpha_N}\sum\limits_{i=n+1}^\infty X_i}_{\sigma_{n+1}-messbar}\ \ \forall n\in\N$\\
$A=\bigcap\limits_{n=1}^\infty\underbrace{\lbrace\alpha_N\sum\limits_{i=n}^NX_i\xrightarrow[N\rightarrow\infty]{}0\rbrace}_{\in T_n}\in T_\infty$\QED
Inbesondere gilt:\\
$P(\lbrace\lim\limits_{n\rightarrow\infty}\dfrac{1}{n}\sum\limits_{i=1}^n(X_i-E(X_i))=0\rbrace)\in\lbrace 0,1\rbrace$\\
für alle unabhängigen Folgen von Zufallsvariablen mit endlichem Erwartungswert, das heißt ein starkes Gesetz der Großen Zahlen gilt entweder fast sicher oder \glqq fast sicher nicht\grqq . 





\pagebreak

\section{Konvergenzarten: fast sicher, stochastisch, in Lp}
$\left(X_n\right)_{n\in\N}$ sei nun stets eine Folge von Zufallsvariablen und $X$ eine Zufallsvariable mit $X-n, X:\left(\Omega,\theta,P\right)\rightarrow\left(\R^d,B\left(\R^d\right)\right)$.\\
Dann gilt \[\underbrace{\lbrace\lim\limits_{n\rightarrow\infty}X_n=X\rbrace}_{\glqq \text{Menge aller }\omega\text{, sodass }\lim\text{ existiert und gleich X ist}\grqq}\in\theta\]

\subsection{Definition (Verschiedene Konvergenzarten (p,f.s.,Lp))}
Wir sagen \begin{enumerate}
\item $X_n$ konvergiert p-fast sicher gegen X, falls
\[P\left(\lbrace\lim\limits_{n\rightarrow\infty}X_n=X\rbrace\right)=1,\ \text{ in Zeichen } X_n\xrightarrow{f.s.}X\].
\item $X_n$ konvergiert stochastisch in Wahrscheinlichkeit gegen $X$, falls \[ P\left(\Vert X_n-X\Vert >\varepsilon\right)\xrightarrow[n\rightarrow\infty]{}0\ \forall\varepsilon > 0\text{ in Zeichen } X_n\xrightarrow{p}X\].
\item $X_n$ konvergiert in $mc{L}^p\left(P\right)$ gegen X für $p\in(0,\infty)$, falls \begin{list}{}{}
\item $\Vert X_n \Vert , \Vert X \Vert \in \mc{L}^p\ \forall n \in \N\ \  (E(\Vert X_n\Vert )<\infty, E(\Vert X \Vert)<\infty)$
\item $E(\Vert X_n-X \Vert^p)\xrightarrow[n\rightarrow\infty]{}0$ 
\end{list}
in Zeichen $X_n\xrightarrow{\mc{L}^p}X$
\item $X_n$ konvergiert in $\mc{L}^\infty\left(P\right)$ gegen X, falls \begin{list}{}{}
\item $\Vert X_n \Vert_\infty , \Vert X \Vert_\infty <\infty\ (d.h.\ X_n,X\in \mc{L}^\infty)\ \forall n\in\N$
\item $E(\Vert X_n-X \Vert_\infty)\xrightarrow[n\rightarrow\infty]{}0$ \\
wobei für eine Zufallsvariable $Y\in\R^d$ gilt 
\end{list}
\[\Vert Y \Vert_\infty = \inf\limits_{c\in\R}\lbrace \Vert Y \Vert < c\ P-f.s\rbrace\]
\end{enumerate}


\subsection{Lemma}






\marginpar{3. Vorlesung 19.04.2018}
Es gilt \begin{enumerate}[label=(\alph*)]
\item $\xrightarrow{f.s.}\Rightarrow\xrightarrow{p}$
\item $\xrightarrow{\mc{L}^p}\Rightarrow\xrightarrow{p}\ \forall p\in (0,\infty]$
\end{enumerate}

\textbf{Beweis}
Sei $\varepsilon>0$ beliebig. Setze $A_n=\lbrace\Vert X_n-X\Vert>\varepsilon\rbrace$\begin{enumerate}[label=(\alph*)]
\item $\lsup \equalto{P\brc{\norm{X_n-X}>\varepsilon}}{E\brc 1_{\brac{\norm{X_n-X}>\varepsilon}}}\myeq[\leq]{Fatou}\equalto{P\brc{\lsup\brac{\norm{X_n-X}>\varepsilon}}}{E\brc{\lsup 1_{\brac{\norm{X_n-X}>\varepsilon}}}} \\= P\brc{\norm{X_n-X}>\varepsilon\text{ für }\infty\text{-viele n}}=0$\\
$\brc{\text{Beachte }\lsup 1_{A_n}=1_{\lsup A_n}}$
\item $p<\infty:\ P\brc{A_n}=\int 1_{A_n}dP\leq\varepsilon^{-p}\int \norm{X_n-X}^pdP\rightarrow 0 für n\rightarrow\infty\\
p=0:\ $ offensichtlich \QED
\end{enumerate}

\subsection{Bemerkung}
\begin{enumerate}[label=(\alph*)]
\item Die Umkehrungen in Lemma 2.2 sind im Allgemeinen falsch
\item Bei allen Konvergenzarten aus der Definition 2.1. ist der Grenzwert (nur) fast sicher eindeutig:
Gelte $X_n\xrightarrow{p}X, X_n\xrightarrow{p}Y\\
\Rightarrow P(\Vert X-Y\Vert >2\varepsilon) \\
\leq P(\Vert X_n-X\Vert + \Vert X_n-Y\Vert > 2\varepsilon)\\
\leq P(\lbrace\Vert X_n-X\Vert > \varepsilon\rbrace\cup\lbrace\Vert X_n-Y\Vert > \varepsilon\rbrace)\\
\leq P(\lbrace\Vert X_n-X\Vert > \varepsilon\rbrace)+P(\lbrace\Vert X_n-Y\Vert > \varepsilon\rbrace)\xrightarrow{n\rightarrow\infty}0\\
\Rightarrow P(\Vert X-Y \Vert>0)=0\\
\Rightarrow X\xlongequal{f.s.} Y$\\
In der Regel vernachlässigt man Unterschiede auf Nullmengen und nennt f.s. gleiche Zufallsvariablen einfach nur gleich. Formell sollte man (wie in Maßtheorie durchgeführt) bei diesen konvergenzarten Äquivalenzklassen fast sicher gleicher Zufallsvariablen betrachten, aber auch das vernachlässigt man fast immer in der Stochastik.
\item Aus der Maßtheorie ist bekannt:\begin{list}{}{}
	\item $(\mc{L}^\infty(P),\Vert\cdot\Vert_\infty)$ ist ein Banachraum
	\item $(\mc{L}^p(P),\Vert\cdot\Vert_p)$ mit $\Vert X\Vert_p:=(E(\Vert x\Vert^p)^{\dfrac{1}{p}}$ ist ein Banachraum für $p\in[1,\infty)$ und $\mc{L}^p(P)^\ast\xlongequal{\text{isometrisch isomorph}}\mc{L}^q(P)\text{ mit }\dfrac{1}{p}+\dfrac{1}{q}=1$\\
 Sei $Y \in \mc{L}^q$, dann ist $Y:\mc{L}^p\rightarrow\R, X\mapsto E(X^TY))$
 \item $(\mc{L}^2(P),\Vert\cdot\Vert_2)$ ist ein Hilbertraum mit Skalarprodukt $(X,Y)\mapsto E(X^TY)$.
\end{list}
\item Man kann zeigen: \\
$\mc{L}^p$ ist für $p\int (0,1)$ ein vollständiger metrischer Raum mit Metrik $d(X,Y)=E(\Vert X-Y\Vert^p)$
\item Da $P(\Omega)=1$ gilt $\mc{L}^q\subseteq \mc{L}^p\ \forall p,q\in\R^+$ mit $q^p$
\item Fast sichere Konvergenz ist nicht metrisierbar.
\end{enumerate}

\subsection{Satz (Äquivalenz zu Konvergenz in p)}
Sei $(X_n)_{n\in\N}$ eine Folge von Zufallsvariablen und X eine Zufallsvariable. Dann sind äquivalent:\begin{enumerate}[label=(\alph*)]
\item $X_n\xrightarrow{p}X\ ,n\rightarrow\infty$
\item Für jede Teilfolge $(n_k)_{k\in\N}\text{ von }\N\ \exists\text{ eine Teilfolge dieser Teilfolge }(n_{k_l})_{l\in\N}$ mit $X_{n_{k_l}}\xrightarrow[l\rightarrow\infty]{f.s.}X$.
\item $d(X_n,X):=E(1\wedge \Vert X_n-X\Vert	)\xrightarrow[n\rightarrow\infty]{}0$
\end{enumerate}

\textbf{Beweis}\\
\begin{list}{}{}
\item $a)\Ra b)$\\
Sei $\folge{n}{k}$ beliebig.Für $j\in\N\ \exists n_0\brc{j}$, so dass $\forall n_k\geq n_0\brc{j}$ gilt  $P\brc{\norm{X_{n_k}-X}>\dfrac{1}{j}}\leq\dfrac{1}{j^2}\\
\Ra \exists$ Teilfolge $\lbrace n_{k_j}\rbrace_{j\in\N}$ mit \\
$P\brc{\norm{X_{n_{k_j}}-X}>\dfrac{1}{j}}\leq\dfrac{1}{j^2}\ \forall j\in\N\\
\Ra \sm{j=1}P\brc{\norm{X_{n_{k_j}}}>\dfrac{1}{j}}\leq\sm{j=1}\dfrac{1}{j^2}<\infty\\
\xRightarrow{Borel-Cantelli}P\brc{\underbrace{\linf[j]\brac{\norm{X_{n_{k_j}}-X}}\leq\dfrac{1}{j}}_{=A}}=1\\
\Ra X_{n_{k_j}}\brc{\omega}\xrightarrow{j\rightarrow\infty} X\brc{\omega}\forall\omega\in A\\
\Ra X_{n_{k_j}}\xrightarrow{f.s.}X,\ j\rightarrow\infty$
\item $b) \Ra a)$\\
Für $\varepsilon>0$ beliebig setze $a:=\lsup \underbrace{P\brc{\norm{X_n-X}>\varepsilon}}_{=:a_n}\\
\Ra \exists$ Teilfolge $\folge{n}{k}$ mit $a_{n_k}\xrightarrow{n\rightarrow\infty}a$\\
Mit b) gibt es eine weitere Teilfolge $\left(n_{k_j}\right)_{j\in\N}$ mit $X_{n_{k_j}}\xrightarrow{f.s.}X,\ n\rightarrow\infty,\ \xRightarrow[\text{Lemma 2.2 a)}]{Beweis}a_{n_{k_j}}\xrightarrow{n\rightarrow\infty}0\\
\Ra a_{n_k}\rightarrow 0 \Ra a=0$
\item $c)\Ra a)$\\
analog zu Lemma 2.2b)
\item $a)\Ra c)$\\
folgt sofort aus dem kommenden Lemma 2.14\QED
\end{list}
\subsection{Bemerkung}
Der Raum $(\mc{L}^0)$ aller Zufallsvariablen mit Metrik $d(X,Y)=E(1\wedge\Vert X-Y\Vert)$ ist ein vollständiger metrischer Raum und mit Satz 2.4 entspricht konvergenz in diesem der stochastischen Konvergenz von Zufallsvariablen.

\subsection{Korollar (Stetigkeitssatz für Konvergenz in Wahrscheinlichkeit, continuous mapping theorem}
\begin{enumerate}[label=(\alph*)]
\item Sei $(X_n)_{n\in\N}$ eine Folge $\R^d$-wertiger Zufallsvariablen, $X$ eine $\R^d$-wertige Zufallsvariable und $f:\R^d\rightarrow\R^m$ für $m\in\N$ stetig.\\
Dann gilt $X_n\xrightarrow{p}X\Rightarrow f(X_n)\xrightarrow{p}f(X)$
\item Seien $X,\ Y$ zwei Zufallsvariablen, $(X_n)_{n\in\N},(Y_n)_{n\in\N}$ zwei Folgen von Zufallsvariablen mit $X_n\xrightarrow{p}X,Y_n\xrightarrow{p}Y$.\\
Dann gilt $X_n+Y_n\xrightarrow{p}X+Y,\ X_n*Y_n\xrightarrow{p}X*Y$
\end{enumerate}

\textbf{Beweis}\\
\begin{enumerate}[label=(\alph*)]
\item Die Aussage gilt offensichtlich für $\xrightarrow{f.s.}$, es genügt Satz 2.4 $a)\Leftrightarrow b)$ anzuwenden.	
\item 
$\norm{\mat{X_n\\Y_n}-\mat{X\\Y}}\leq C\brc{\norm{X_n-X}+\norm{Y_n-Y}}$ für $C$ geeignet.\\
$P\brc{\norm{\mat{X_n\\Y_n}-\mat{X\\Y}}>\varepsilon}\leq P\brc{\brc{\norm{X_n-X}+\norm{Y_n-Y}}>\dfrac{\varepsilon}{C}} \\
\leq P\brc{\brc{\norm{X_n-X}}>\dfrac{\varepsilon}{2C}}+P\brc{\brc{\norm{Y_n-Y}}>\dfrac{\varepsilon}{2C}} \\
\Ra \mat{X_n\\Y_n}\xrightarrow{p}\mat{X\\Y}$\\
Nun folgt b) direkt aus a)\QED

\end{enumerate}

Wann $\xrightarrow{f.s}$ Konvergenz Konvergenz in $\mathcal{L}^p$ impliziert, folgt unmittelbar aus diversen Resultaten zur Integralkonvergenz, die in Maßtheorie gezeigt wurden. Wir fassen diese kurz aus stochastischer Sicht zusammen.
\subsection{Satz (Beppo-Levy)}
Seien $(X_n)_{n\in\N},\ X$ reellwertige Zufallsvariablen mit $X_n\nearrow_{f.s.}X$.\\ 
Dann gilt $E(X_n)\nearrow_{n\rightarrow\infty}E(X)$. \\(Beachte: gegebenenfalls sind alle Erwartungswerte $\infty$).




\subsection{Lemma (Fatou)}
\marginpar{4. Vorlesung 23.04.2018}
\begin{enumerate}[label=(\alph*)]
\item Seien $\folge{X}{n}$ nichtnegative Zufallsvariablen, so gilt\\
$E\brc{\linf X_n}\leq\linf{E(X_n)}$
\item Seien $\folge{X}{n}$ nichtnegative Zufallsvariablen. Existiert eine Zufallsvariable  $X\in \mc{L}^1$ mit $X_n\leq X$ f.s. $\forall n\in\N$ so gilt \\
$E\brc{\lsup X_n}\geq\lsup{E\brc{X_n}}$
\end{enumerate}

\subsection{Satz (Dominierte Konvergenz)}
Seien $\folge{X}{n},X$ Zufallsvariablen mit $X_n\xrightarrow{f.s.}X$ und $\norm{X}\leq Y$ f.s. für ein $Y\in \mc{L}^1$. Dann gilt\\
$X_n\xrightarrow{\mathcal{L}^1}X$ und $E(X_n)\xrightarrow{n\rightarrow\infty}E(X)$.

\subsection{Satz (Vitali)}
Seien $\folge{X}{n},X$ Zufallsvariablen mit $X_n\xrightarrow{f.s.}X$ und $\lsup\norm{X_n}_p\leq\norm{X}$ für ein $p\in(1,\infty)$. Dann gilt $X_n\xrightarrow{\mathcal{L}^p}X$.\\
Weitere wichtige Konvergenzsätze nutzen das Konzept der Gleichgradigen Integrierbarkeit (uniform integrability).

\subsection{Definition (Gleichgradige Integrierbarkeit)}
Sie $\mc{I}$ eine Indexmenge. Eine Familie $\folge[\mc{I}]{X}{i}$ von Zufallsvariablen heißt \underline{gleichgradig integrierbar}, (UI), falls\\ $\forall\varepsilon>0\ \exists k>0:\ E\brc{\norm{X_i}1_{\brac{\norm{X_i}>k}}}<\varepsilon\ \forall i\in\mc{I}$

\subsection{Lemma (Einelementige Familien sind UI)}
Sei $X\in\mc{L}^1$. Dann $\forall\varepsilon>0\ \exists k>0:\ E\brc{\norm{X}1_{\brac{\norm{X}>k}}}<\varepsilon$, d.h. jede einelementige Familie integrierbarer Zufallsvariablen ist gleichgradig integrierbar.
\textbf{Beweis}
Es gilt $\norm{X}1_{\brac{\norm{X}>k}}\xrightarrow[k\rightarrow\infty]{f.s.}0$ und $\norm{X}1_{\brac{\norm{X}>k}}\leq \norm{X}\in\lp{1}$. \\
Dominierte Konvergenz ergibt somit \\
$E\brc{\norm{X}1_{\brac{\norm{X}>k}}}\xrightarrow{k\rightarrow\infty}0$\QED

\subsection{Lemma (UI => Beschränkt)}
Eine UI Familie von Zufallsvariablen ist beschränkt in $\lp{1}$.\\
\beweis
Sei K so,dass $E\brc{\norm{X_i}1_{\brac{\norm{X_i}>k}}}<1\ \forall i\in\mc{I}.\\
\norm{X_i}_1\leq E\brc{\norm{X}1_{\brac{\norm{X}\leq k}}}+E\brc{\norm{X}1_{\brac{\norm{X}>k}}}\leq k+1$.\\
Die Umkehrung gilt nicht.

\subsection{Lemma}
\begin{enumerate}[label=(\alph*)]
\item Ist eine Familie von Zufallsvariablen beschränkt in $\lp{p}$ f+r $p>1$, so ist sie UI.
\item Sei $\folge[\mc{I}]{X}{i}$ eine Familie von Zufallsvariablen, $Y\int\lp{1}$ mit $\norm{X_i}\leq Y$ f.s. $\forall i \in\mc{I}$. Dann ist $\folge[\mc{I}]{X}{i}$ UI.\\
\end{enumerate}
\beweis
\begin{enumerate}[label=(\alph*)]
\item $A:=\sup\limits_{i\in\mc{I}}E\brc{\norm{X_i}^p}.$ Seien  $v\geq k >0$. Offensichtlich gilt $E\brc{\norm{X_i}1_{\brac{\norm{X_i}>k}}}\leq k^{1-p}E\brc{\norm{X_i}^p1_{\brac{\norm{X_i}>k}}}\leq k^{1-p}A$
\item Offenstichtlich, da $E\brc{\norm{X_i}1_{\brac{\norm{X_i}>k}}}\leq E\brc{Y1_{\brac{\norm{X_i}>k}}}$
\end{enumerate}

\subsection{Lemma (Beschränkte Konvergenz)}
Sei $\folge{X}{n}$ eine Folge von Zufallsvariablen und X eine Zufallsvariable. Falls $X_n\xrightarrow[n\rightarrow\infty]{p}X$ und ein $k\geq 0$ existiert mit $\norm{X_n(\omega)}\leq k\ \forall n\in\N,\omega\in\Omega,$ so gilt $X_n\xrightarrow[n\rightarrow\infty]{\lp{1}}X$ und insbesondere $E(X_n)\xrightarrow[n\rightarrow\infty]E(X)$\\
\beweis
Zunächst zeigen wir $P\brc{\norm{X}\leq k}=1$. \\
Für $k\in\N$ gilt \\
$P\brc{\norm{X}>K+k^{-1}}\leq P\brc{\norm{X-X_n}>k^{-1}}\ \forall n\in\N\\
\Ra P\brc{\norm{X}>k+k^{-1}}=0\\
\Ra P\brc{\norm{X}>k}=P\brc{\CUP[]{k\in\N}\brac{\norm{X}>k+k^{-1}}}=0$.\\
Sei nun $\varepsilon>0$. Wähle $n_0$ so, dass \[P\brc{\norm{X_n-X}>\dfrac{\varepsilon}{3}}<\dfrac{\varepsilon}{3k}\ \forall n\geq n_0\]
Dann gilt $\forall n\geq n_0:\\
E\brc{\norm{X_n-X}}\leq E\brc{\norm{X_n-X}\1{\brac{\norm{X_n-X}}>\dfrac{\varepsilon}{3}}+\dfrac{\varepsilon}{3}\leq 2kP\brc{\xn>\dfrac{\varepsilon}{3}}+\dfrac{\varepsilon}{3}$
\end{document}